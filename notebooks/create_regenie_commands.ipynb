{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import scrapbook as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path.append(\"/home/jupyter/packages/\")\n",
    "#import regenie_writer_functions.regenie_writer_functions as rw\n",
    "from src import regenie_writer_functions as rw\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Each run is identified by the run_name, cohort and phenotype\n",
    "'''\n",
    "run_name = \"allofus_cad_eur\"\n",
    "cohort = \"allofus_eur\"\n",
    "phenotype_names = \"cad\" #if multiple seperated by ';' should match exactly as given in associations_tracker sheet\n",
    "metafile = \"NA\" #if reading from google sheet, metafile = \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "# Get the number of CPU cores\n",
    "num_cores = cpu_count() - 1\n",
    "threads = min(31, num_cores) #after 31 cores performance starts to plateu, may be more useful to do xargs -P\n",
    "print(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "GLOBAL VARS & READ IN CONFIG FILE\n",
    "'''\n",
    "path_2_config = \"/home/jupyter/regenie_dependencies/config.json\"\n",
    "regenie_params = utils.get_config_parameter(\"regenie_defaults\", path_2_config)\n",
    "google_sheet = utils.get_config_parameter(\"google_sheet\", path_2_config)\n",
    "plink_path = utils.get_config_parameter(\"plink\", path_2_config)[\"path\"]\n",
    "\n",
    "REGENIE = regenie_params[\"REGENIE_PATH\"] #this should be present as an executable in your path\n",
    "BSIZE = regenie_params[\"BSIZE\"]\n",
    "CASE_CONTROL_IMBALANCE = regenie_params[\"CASE_CONTROL_IMBALANCE_HANDLE\"]\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y_%m_%d__%H:%M\")\n",
    "\n",
    "base_output_file_name = \"_\".join([run_name, cohort, \"_\".join(phenotype_names.split(\";\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Read in meta-file\n",
    "'''\n",
    "if metafile == \"NA\":\n",
    "    google_sheet_id = google_sheet[\"id\"]\n",
    "    regenie_tracker_sheet = google_sheet[\"name\"]\n",
    "    regenie_tracker_sheet_url = google_sheet[\"link\"].format(google_sheet_id, regenie_tracker_sheet)\n",
    "\n",
    "    regenie_df = pd.read_csv(regenie_tracker_sheet_url)\\\n",
    "    .query(\"cohort == '{}'\".format(cohort))\\\n",
    "    .query(\"phenotype_names == '{}'\".format(phenotype_names))\\\n",
    "    .query(\"run_name == '{}'\".format(run_name))\\\n",
    "    .reset_index()\n",
    "else:\n",
    "     regenie_df = pd.read_csv(metafile)\\\n",
    "     .query(\"cohort == '{}'\".format(cohort))\\\n",
    "     .query(\"phenotype_names == '{}'\".format(phenotype_names))\\\n",
    "     .query(\"run_name == '{}'\".format(run_name))\\\n",
    "     .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#each run_name, cohort, phenotype combination should be unique in the tracking sheet\n",
    "assert regenie_df.shape[0] == 1, \"Values specified != 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "regenie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Read in all params\n",
    "'''\n",
    "input_params = regenie_df.to_dict()\n",
    "\n",
    "'''\n",
    "path params\n",
    "'''\n",
    "base_path = input_params[\"base_path\"][0]\n",
    "output_path = input_params[\"output\"][0]\n",
    "\n",
    "'''\n",
    "phenotype params\n",
    "'''\n",
    "trait_type = input_params[\"trait_type\"][0]\n",
    "phenotype_files_string = input_params[\"phenotypes_file\"][0]\n",
    "samples_to_keep_file = input_params[\"samples_to_keep_file\"][0]\n",
    "rint = input_params[\"rint\"][0]\n",
    "\n",
    "'''\n",
    "covariates params\n",
    "'''\n",
    "age_col_string = input_params[\"covariates:age\"][0]\n",
    "categorical_cols_string = input_params[\"covariates:categorical\"][0]\n",
    "binary_qt_cols_string = input_params[\"covariates:binary_qt\"][0]\n",
    "pc_covariates_string = input_params[\"covariates:PCs\"][0]\n",
    "quadratic_age_sex = input_params[\"add_quadratic_age_sex\"][0]\n",
    "\n",
    "'''\n",
    "Step 1 specific params\n",
    "'''\n",
    "bgen_step1_file = input_params[\"bgen_step1\"][0]\n",
    "step1_vars = input_params[\"step1_vars\"][0]\n",
    "loco_predictions = input_params[\"loco_predictions\"][0]\n",
    "subset_step1_vars = input_params[\"subset_step1_file\"][0]\n",
    "\n",
    "'''\n",
    "Step 2 specific params\n",
    "'''\n",
    "bgen_step2_file = input_params[\"bgen_step2\"][0]\n",
    "step2_vars = input_params[\"step2_vars\"][0]\n",
    "model = input_params[\"model\"][0]\n",
    "step2_run_type = input_params[\"step2_run_type\"][0]\n",
    "\n",
    "'''\n",
    "Gene burden / Skat test params \n",
    "Currently only works for Gene burdens\n",
    "'''\n",
    "anno_file = input_params[\"anno_file\"][0]\n",
    "set_list = input_params[\"set_list\"][0]\n",
    "mask_defs = input_params[\"mask_defs\"][0]\n",
    "aafs = \",\".join(str(input_params[\"aafs\"][0]).split(\";\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Check required params exist\n",
    "'''\n",
    "required_params = [trait_type, base_path, output_path, phenotype_files_string]\n",
    "\n",
    "required_params_check = [ x for x in required_params if pd.isna(x) ]\n",
    "\n",
    "assert len(required_params_check) == 0, \"required params missing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Read in phenotype files\n",
    "subset to cohort of interest\n",
    "if samples file given, subset to samples of interest\n",
    "'''\n",
    "phenotype_files = phenotype_files_string.split(\";\")\n",
    "phenotype_dfs = []\n",
    "for phenotype_file in phenotype_files:\n",
    "    temp_pheno = pd.read_csv(base_path + \"/\" + phenotype_file)\n",
    "    if \"cohort\" in temp_pheno.columns: #subsetting to cohort to avoid multiple files with same name\n",
    "        temp_pheno = temp_pheno.query(\"cohort == '{}'\".format(cohort))\n",
    "    phenotype_dfs.append(temp_pheno.set_index(\"sampleId\"))\n",
    "\n",
    "phenotype_df = pd.concat(phenotype_dfs, axis = 1, verify_integrity = True)\\\n",
    ".query(\"cohort == '{}'\".format(cohort))\n",
    "\n",
    "if pd.notnull(samples_to_keep_file):\n",
    "    samples_df = pd.read_csv(\"/\".join([base_path, samples_to_keep_file]), usecols = {\"sampleId\"}).set_index(\"sampleId\")\n",
    "    phenotype_df = pd.merge(phenotype_df, samples_df, on = [\"sampleId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parse covariates input and generate covariates file\n",
    "IMPORTANT: Any row with null values will be dropped\n",
    "'''\n",
    "\n",
    "categorical_cols = rw.splitIfExists(categorical_cols_string)\n",
    "age_col = rw.splitIfExists(age_col_string)[0]\n",
    "binary_qt_cols = rw.splitIfExists(binary_qt_cols_string)\n",
    "pc_covariates = rw.splitIfExists(pc_covariates_string)\n",
    "\n",
    "pc_cols_to_add = []\n",
    "for pc_col in pc_covariates:\n",
    "    pc_covars = rw.processPCInput(pc_col)\n",
    "    pc_cols_to_add.extend(pc_covars)\n",
    "\n",
    "covariate_cols_merged = [age_col] + binary_qt_cols + categorical_cols + pc_cols_to_add\n",
    "\n",
    "covariates_df = rw.createAnalysisReadyFiles(phenotype_df[covariate_cols_merged].dropna())\n",
    "\n",
    "cat_covars = categorical_cols\n",
    "covar_lists = [age_col] + binary_qt_cols + pc_covariates\n",
    "\n",
    "'''\n",
    "Add age^2 and age*sex columns if add_quadratic_age_sex is not specifically set to False\n",
    "'''\n",
    "if str(quadratic_age_sex).lower() != \"no\":\n",
    "    covariates_df[\"age2\"] = covariates_df[age_col] * covariates_df[age_col]\n",
    "    covariates_df[\"age_sex\"] = covariates_df[age_col] * covariates_df[\"sex\"]\n",
    "    covar_lists = covar_lists + [\"age2\", \"age_sex\"]\n",
    "    \n",
    "covariates_file_name = \"/\".join([base_path, output_path, base_output_file_name + \"_covariates.tsv\"])\n",
    "\n",
    "covariates_df.to_csv(covariates_file_name, sep = \"\\t\", index = False)\n",
    "print(\"covariates DF: {}\".format(covariates_file_name))\n",
    "print(\"Categorial covariates: {}\".format(\",\".join(cat_covars)))\n",
    "print(\"Quant covariates: {}\".format(\",\".join(covar_lists)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create phenotypes_df\n",
    "'''\n",
    "analysis_ready_phenotypes_df = rw.createAnalysisReadyFiles(phenotype_df[phenotype_names.split(\";\")].dropna())\n",
    "\n",
    "phenotypes_file_name = \"/\".join([base_path, output_path, base_output_file_name + \"_phenotypes.tsv\"])\n",
    "                                \n",
    "analysis_ready_phenotypes_df.to_csv(phenotypes_file_name, sep = \"\\t\", index = False)\n",
    "print(\"Phenotypes DF: {}\".format(phenotypes_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_ready_phenotypes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Add code below to view phenotypes and covariates\n",
    "Get number of missing values overall cases/controls\n",
    "If BT: median and means of cases and controls\n",
    "If QT: pearson correlations and R-squared between outcome and covariates\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Write out step 1 command\n",
    "'''\n",
    "if str(loco_predictions) == 'nan':\n",
    "    step1_command_file = \"/\".join([base_path, output_path, base_output_file_name + \"_step1_command\"])\n",
    "    step1_f=open(step1_command_file, 'w+')\n",
    "    #if needed subset variants to keep using plink\n",
    "    variants_to_keep_step1_file = step1_vars\n",
    "    \n",
    "    if subset_step1_vars == 'yes':\n",
    "        samples_file = \"/\".join([base_path, output_path, base_output_file_name + \"_samples_in_analysis.tsv\"])\n",
    "        variants_to_keep_step1_file = \"/\".join([output_path, base_output_file_name + \"_variants_to_keep.snplist\"])\n",
    "        \n",
    "        analysis_ready_phenotypes_df[\"FID\"].to_csv(samples_file, sep = \"\\t\", index = False, header = False)\n",
    "        print(\"## PLINK PRE-PROCESSING STEP ##\", file=step1_f)\n",
    "        print(\"{} \\\\\".format(plink_path), file=step1_f)\n",
    "        print(\"--bgen {}/{} ref-first \\\\\".format(base_path, bgen_step1_file) , file=step1_f)\n",
    "        print(\"--keep {} \\\\\".format(samples_file) , file=step1_f)\n",
    "        print(\"--extract {}/{} \\\\\".format(base_path, step1_vars) , file=step1_f)\n",
    "        print(\"--mac 50 --write-snplist \\\\\", file=step1_f)\n",
    "        print(\"--threads {} \\\\\".format(threads) , file=step1_f)\n",
    "        print(\"--out {}/{}\".format(base_path, variants_to_keep_step1_file.split(\".snplist\")[0]), file=step1_f)\n",
    "        print(\" \", file=step1_f)\n",
    "        print(\"## END PLINK PRE-PROCESSING STEP ##\", file=step1_f)\n",
    "        print(\" \", file=step1_f)\n",
    "    \n",
    "    rw.printRegenieHouseKeeping(file_handle = step1_f, \\\n",
    "                             step = \"1\", \\\n",
    "                             phenotypes = phenotype_names, \\\n",
    "                             cohort = cohort, \\\n",
    "                             run_name = run_name, \\\n",
    "                             date_time = dt_string,\n",
    "                             regenie_path = REGENIE,\n",
    "                             threads = threads)\n",
    "\n",
    "    rw.printRegenieExtractions(file_handle = step1_f, \\\n",
    "                            base_path = base_path, \\\n",
    "                            bgen_file = bgen_step1_file, \\\n",
    "                            vars_to_extract = variants_to_keep_step1_file, \\\n",
    "                            phenotypes_file_name = phenotypes_file_name, \\\n",
    "                            covariates_file_name = covariates_file_name, \\\n",
    "                            cat_covars = cat_covars, \\\n",
    "                            covar_lists = covar_lists, \\\n",
    "                            trait_type = trait_type.lower(), \\\n",
    "                            rint = str(rint).lower())\n",
    "    '''\n",
    "    print out step 1 specific commands\n",
    "    '''\n",
    "    print(\"--lowmem \\\\\", file=step1_f)\n",
    "    print(\"--loocv \\\\\", file=step1_f)\n",
    "    print(\"--step 1 \\\\\", file=step1_f)\n",
    "    print(\"--out {}/{}/{}\".format(base_path, output_path, base_output_file_name), file=step1_f)\n",
    "    \n",
    "    step1_f.close()\n",
    "    loco_predictions_file = \"{}/{}/{}_pred.list\".format(base_path, output_path, base_output_file_name)\n",
    "\n",
    "else:\n",
    "    loco_predictions_file = loco_predictions\n",
    "    \n",
    "print(loco_predictions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "step2_command_file = \"/\".join([base_path, output_path, base_output_file_name + \"_step2_command\"])\n",
    "step2_f=open(step2_command_file, 'w+')\n",
    "\n",
    "if str(step2_run_type) == \"nan\" or str(\"step2_run_type\") == \"step2_only_w_loco\":\n",
    "    step2_results = \"{}/{}/{}\".format(base_path, output_path, base_output_file_name + \"_sm_results\")\n",
    "    rw.printRegenieHouseKeeping(file_handle = step2_f, \\\n",
    "                             step = \"2\", \\\n",
    "                             phenotypes = phenotype_names, \\\n",
    "                             cohort = cohort, \\\n",
    "                             run_name = run_name, \\\n",
    "                             date_time = dt_string,\n",
    "                             regenie_path = REGENIE,\n",
    "                             threads = threads)\n",
    "\n",
    "    rw.printRegenieExtractions(file_handle = step2_f, \\\n",
    "                            base_path = base_path, \\\n",
    "                            bgen_file = bgen_step2_file, \\\n",
    "                            vars_to_extract = step2_vars, \\\n",
    "                            phenotypes_file_name = phenotypes_file_name, \\\n",
    "                            covariates_file_name = covariates_file_name, \\\n",
    "                            cat_covars = cat_covars, \\\n",
    "                            covar_lists = covar_lists, \\\n",
    "                            trait_type = trait_type.lower(), \\\n",
    "                            rint = str(rint).lower())\n",
    "    print(\"--minMAC 0.5 \\\\\", file=step2_f) #put this in regeniestep2 function\n",
    "    rw.printRegenieStep2(file_handle = step2_f, \\\n",
    "                         base_path = base_path, \\\n",
    "                         cohort = cohort, \\\n",
    "                         run_name = run_name, \\\n",
    "                         model = model, \\\n",
    "                         loco_predictions = loco_predictions_file, \\\n",
    "                         trait_type = trait_type.lower(), \\\n",
    "                         output_file = step2_results)\n",
    "    step2_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "step2_gb_command_file = \"/\".join([base_path, output_path, base_output_file_name + \"_step2_gb_command\"])\n",
    "\n",
    "if str(anno_file) != \"nan\":\n",
    "    step2_gb_f=open(step2_gb_command_file, 'w+')\n",
    "    step2_gb_results = \"{}/{}/{}\".format(base_path, output_path, base_output_file_name + \"_gb_results\")\n",
    "    \n",
    "    rw.printRegenieHouseKeeping(file_handle = step2_gb_f, \\\n",
    "                             step = \"2 GeneBurdens\", \\\n",
    "                             phenotypes = phenotype_names, \\\n",
    "                             cohort = cohort, \\\n",
    "                             run_name = run_name, \\\n",
    "                             date_time = dt_string,\n",
    "                             regenie_path = REGENIE,\n",
    "                             threads = threads)\n",
    "\n",
    "    rw.printRegenieExtractions(file_handle = step2_gb_f, \\\n",
    "                            base_path = base_path, \\\n",
    "                            bgen_file = bgen_step2_file, \\\n",
    "                            vars_to_extract = step2_vars, \\\n",
    "                            phenotypes_file_name = phenotypes_file_name, \\\n",
    "                            covariates_file_name = covariates_file_name, \\\n",
    "                            cat_covars = cat_covars, \\\n",
    "                            covar_lists = covar_lists, \\\n",
    "                            trait_type = trait_type.lower(), \\\n",
    "                            rint = str(rint).lower())\n",
    "    print(\"--minMAC 0.5 \\\\\", file=step2_gb_f) #put this in regeniestep2 function\n",
    "    rw.printRegenieStep2(file_handle = step2_gb_f, \\\n",
    "                         base_path = base_path, \\\n",
    "                         cohort = cohort, \\\n",
    "                         run_name = run_name, \\\n",
    "                         loco_predictions = loco_predictions_file, \\\n",
    "                         trait_type = trait_type.lower(), \\\n",
    "                         output_file = step2_gb_results, \\\n",
    "                         model = model, \\\n",
    "                         anno_file = anno_file, \\\n",
    "                         set_list = set_list, \\\n",
    "                         mask_defs = mask_defs, \\\n",
    "                         aafs = aafs)\n",
    "    step2_gb_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "if str(loco_predictions) == 'nan':\n",
    "    outputs.append(\"step 1 file written: {}\".format(step1_command_file))\n",
    "    print(step1_command_file)\n",
    "if str(bgen_step2_file) != 'nan':\n",
    "    outputs.append(\"step 2 file written: {}\".format(step2_command_file))\n",
    "    print(step2_command_file)\n",
    "if str(anno_file) != \"nan\":\n",
    "    outputs.append(\"step 2 gene_burden file written: {}\".format(step2_gb_command_file))\n",
    "    print(step2_gb_command_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Add code to post-GWAS QC\n",
    "Add code to merge with annotations and add homRR|hetRA|homAA counts for cases and controls\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.glue(\"command_files\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "environment": {
   "kernel": "python3",
   "name": "r-cpu.4-2.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-2:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
